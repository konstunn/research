
\documentclass[a4paper,14pt]{extarticle}

% for ability to highlight\select and copy text from result pdf output to
% clipboard
\usepackage{cmap}

\usepackage{setspace}

\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\usepackage[a4paper,margin=1cm,footskip=.5cm,left=2cm,right=1.5cm,top=1.5cm,
		bottom=1.5cm]{geometry}

\usepackage{textcase}
\usepackage{csquotes}
\usepackage{enumitem}

\usepackage[nottoc]{tocbibind}

% do not show section numbers
%\usepackage[raggedright]{titlesec}

\usepackage{amsmath}

% indent first paragraph in every section
\usepackage{indentfirst}

\usepackage{secdot}

\usepackage[titletoc,title]{appendix}


% indent description items
\setlist[description]{leftmargin=\parindent,labelindent=\parindent}

% ?
%\patchcmd{\appendices}{\quad}{: }{}{}

\setcounter{secnumdepth}{3}
\setstretch{1.5}

\begin{document}

\begin{titlepage}

	\begin{center}
		\MakeTextUppercase{Министерство образования и науки Российской~Федерации}

		\bigbreak

		ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ
			ВЫСШЕГО ОБРАЗОВАНИЯ

		\bigbreak

		\MakeTextUppercase{\enquote{Новосибирский государственный технический
			университет}}
		\vspace{5pt}
		\hrule

		\bigbreak

		Кафедра теоретической и прикладной информатики

		\vspace{50pt}

		\textbf{\LARGE{Отчет по}\\}

		\bigbreak

		производственной практике: \\
			практике по получению профессиональных умений и опыта профессиональной
			деятельности

		\bigbreak

		c 1 ноября по 31 декабря

		\bigbreak

		<<Параметрическая идентификация непрерывно-дискретных стохастических
		динамических линейных систем>>

		\vspace{50pt}

	\end{center}

	\begin{flushleft}
		\begin{tabbing}
			Группа:\qquad\qquad\qquad \= ПММ-61\\
			Студент:                  \> Горбунов К. К.\\
			Место практики:           \> отдел № 8 ФГУП <<СНИИМ>> \\
			Руководитель:             \> нач. отдела № 8, Толстиков А.С.
		\end{tabbing}
	\end{flushleft}

	\begin{center}
		\vspace{\fill}
		Новосибирск, 2016 г.
	\end{center}

\end{titlepage}

\tableofcontents

\newpage

\section*{Введение}
\addcontentsline{toc}{section}{Введение}

В настоящее время математическое моделирование играет фундаментальную роль в
науке и технике и является одним из интенсивно развивающихся перспективных
научных направлений в области информатики.

Проблема идентификации, связанная с построением математических моделей по
экспериментальным данным, относится к одной из основных проблем теории и
практики автоматического управления. Ее качественное решение способствует
эффективному применению на практике современных математических методов и
наукоемких технологий, например, при расчете и проектировании систем управления
подвижными (в том числе авиационно-космическими) и технологическими объектами,
построении прогнозирующих моделей (например, в экономике и бизнес-процессах),
конструировании следящих и измерительных систем \cite{denisov}.

\section{Постановка задачи}

\subsection[Структурно-вероятностное описание модельной структуры]
{Структурно-вероятностное описание модельной \\структуры}

% remember to measure identification accuracy in spaces of outputs and
% parameters
%\noindent $\frac{||\theta^* -\ \hat{\theta}||}{||\theta^*||}$
%\\
%\\
%$\frac{||y^* -\ \hat{y}||}{||y^*||}$
%\\

Определим модель стохастической динамической линейной \\непрерывно-дискретной
системы в простанстве состояний в виде:
\begin{equation}
	\label{eq:initmod}
	\left\{ 
		\begin{array}{lll}
			\frac{d}{dt}x(t) &= F x(t) + C u(t) + G w(t), & t \in [t_0,T] \\ 
			y(t_k)           &= H x(t_k) + v(t_k),        & k = 1,\ldots, N
		\end{array} 
	\right. 
\end{equation}

Здесь:
\begin{description}
	\item [$x(t)$] -- вектор состояния;
	\item [$F$] -- матрица перехода состояния;
	\item [$u(t)$] -- вектор-функция управления (входного воздействия);
	\item [$C$] -- матрица управления;
	\item [$w(t)$] -- вектор возмущений;
	\item [$G$] -- матрица влияния возмущений;
	\item [$H$] -- матрица наблюдения;
	\item [$v(t_k)$] -- шум измерений;
	\item [$y(t_k)$] -- вектор наблюдений (измерений) отклика;
\end{description}

В данной модели уравнение объекта является непрерывным, а уравнение наблюдений
--- дискретным. Такая модель является характерной для значительного множества
прикладных задач.

Одной из целей исспедований в рамках магистерской диссертации является
разработка алгоритмов оценивания состояния и идентификации стохастической 
динамической непрерывно-дискретной модели вида \ref{eq:initmod}. 

Один из видимых путей решения задачи оценивания состояния такой системы
является адаптация аналогичных алгоритмов, применимых к дискретным и
непрерывным системам, к данному непрерывно-дискретному случаю.

Разрабатываемый алгоритм также должен оценивать вероятностные характеристики
шумов объекта и измерений, потому как в реальных задачах вероятностные
характеристики данных процессов неизвестны или же эти процессы являются
нестационарными.

\section[Параметрическая идентификация моделей стохастических
\\непрерывно-дискретных систем]
{Параметрическая идентификация моделей \\стохастических
непрерывно-дискретных систем} 

Идентификацией динамической системы называется определение структуры и
параметров математической модели, обеспечивающих наилучшее совпадение выходных
переменных моделей переменных модели и системы при одинаковых входных
воздействиях \cite{chubich}.

Под параметрической идентификацией, в частности, понимается только определение
параметров модели. Предполагается, что структура модели известна.

В данной работе в качестве критерия идентификации используется критерий
максимального правдоподобия, а получаемые оценки параметров модели является
оценками максимального правдоподобия (ОМП).

\subsection{Вычисление значения критерия идентификации}

\newcommand{\eps}{\varepsilon}

Выражение для критерия максимального правдоподобия имеет вид \cite{denisov}:
\begin{equation}
\begin{split}
\chi(\theta) = -\ln{L(Y_1^N;\theta)} = \frac{Nm}{2} \ln{2\pi} +
\\ + \frac{1}{2} \sum\limits_{k=1}^{N} 
\left[ \eps^T(t_k, \theta) B^{-1}(t_k, \theta) \eps(t_k, \theta) + 
\ln \det B(t_k, \theta) \right].
\end{split}
\end{equation}

Здесь:

\begin{description}
\item[$Y_1^N$] --- множество из $N$ наблюдений отклика
\item[$\theta$] --- вектор параметров модели 
\item[$\chi(\cdot)$] --- функционал, используемый в качестве критерия
идентификации
\item[$L(\cdot)$] --- функционал максимального правдоподобия 
\item[$N$] --- число дискретных моментов времени наблюдений
\item[$m$] --- число выходных каналов системы (размерность вектора наблюдений
отклика)
\item[$\eps(t_j) = y(t_j) - H \hat{x}(t_j|t_{j-1})$] --- обновляющая
последовательность 
\item[$B(t_j) = HP(t_j|t_{j-1})H^T + R$] --- ковариационная обновляющей
последовательности 
\end{description}

\newpage
Алгоритм вычисления значения критерия следующий:

\begin{enumerate}
\item Пусть $j = 1$, $\chi(\theta) = 0$.
\item Решаются дифференциальные уравнения непрерывно-дискретного фильтра
Калмана с соответствующими начальными условиями:
\[
\frac{d}{dt}\hat{x}(t|t_{j-1}) = F \hat{x}(t|t_{j-1}) + C u(t),\ 
t_{j-1} \le t \le t_j,\ \hat{x}(t_0|t_0) = \bar{x}_0;
\]
\[
\frac{d}{dt}P(t_j|t_{j-1}) = F P(t|t_{j-1}) + P(t|t_{j-1}) F^T + GQG^T,\\
\]
\[
t_{j-1} \le t \le t_j,\ P(t_0|t_0) = P_0;
\]
Получаем $\hat{x}(t_j|t_{j-1})$ и $P(t_j|t_{j-1})$.

\item Вычисляются
\[ \eps(t_j) = y(t_j) - H \hat{x}(t_j|t_{j-1}); \]
\[ B(t_j) = H P(t_j|t_{j-1}) H^T + R; \]
\[
K(t_j) = P(t_j|t_{j-1}) H^T B^{-1}(t_j).
\]

\item Вычисляется соответствующая $j$-му моменту времени составляющая функции
правдоподобия (2.35)
\[
S = \frac{1}{2} \left[B^{-1}(t_j) \eps(t_j) + \ln \det B(t_j)\right].
\]

\item Накапливается сумма
\[
\chi(\theta) = \chi(\theta) + S.
\]

\item Если $j = N$, то
\[
\chi(\theta) = \chi(\theta) + \frac{Nm}{2} \ln 2\pi
\]
и вычисления прекращаются, иначе --- вычисляются следующие начальные условия по
формулам
\[
\hat{x}(t_j|t_{j-1}) = \hat{x}(t_j|t_{j-1}) + K(t_j) \eps(t_j);
\]
\[
P(t_j|t_{j-1}) = \left[ I - K(t_j) H \right] P(t_j|t_{j-1}),
\]
$j$ заменяется на $j+1$ и осуществляется переход на шаг 2.

\end{enumerate}

\subsection[Вычисление значения градиента критерия идентификации]
{Вычисление значения градиента критерия \\идентификации}

В данной работе предлагается к рассмотрению два практических метода вычисления
значения градиента критерия идентификации: по аналитическому выражению и с
использованием программных средств автоматического дифференцирования.

Далее приведено краткое описание каждого из этих методов.

\subsubsection{Вычисление по аналитическому выражению}

Алгоритм может быть следующим:


\subsubsection{Программный метод автоматического дифференцирования}

Рассматриваемый программный метод берет свое начало из задач машинного обучения
глубоких нейронных сетей, которые в настоящее время являются популярным
объектом научных исследований, образующие целое новое научное направление ---
глубинное обучение. Глубокие нейронные сети применяются для решения широкого
класса практических задач распознавания, классификации, предсказания, обработки
и анализа ествесственных языков и многих других.

Глубокими нейронными сетями называются такие сети, которые имеют в своем
составе большое число скрытых слоев нейронов, и, следовательно, суммарно
большое число нейронов.

Задачу обучения нейронной сети можно трактовать как оценивание параметров этой
сети по некоторым полученным извне наборам данных (наблюдениям), которые
называются обучающими наборами данными. Параметрами сети являются веса связей
между её нейронами. Так как по определению глубокой сети число входящих в неё
нейронов велико, то, соответственно, велико и число <<оцениваемых>> параметров
(весов).

В связи с большим числом параметров (весов) возникают проблемы применимости
методов оценивания с использованием традиционных методов вычисления градиента
функции потерь (критерия) для поиска экстремальных значений. Эти проблемы,
связаны, во-первых, с невозможностью вывода аналитического выражения градиента
для модели со столь большим числом параметров и столь сложной структурой как
нейронная сеть. Во-вторых, методы приближенного вычисления градиента не
позволяют достичь удовлетворительной точности для обеспечения сходимости
оптимизационной процедуры к искомому решению.

Программный метод автоматического дифференцирования или также называемый метод
обратного распространения ошибки основан на правиле дифференцирования сложной
функции (правиле <<цепи>>) и предполагает определения производной для каждой
операции используемой системы компьютерной алгебры. Данный метод позволяет
вычислять градиент быстро и точно, не программируя явно его вычисления. Отсюда
и название метода --- автоматическое дифференцирование.

Наиболее популярные системы, в которых реализовано автоматическое
дифференцирование: TensorFlow, Theano, Torch. Существует большое число других
систем и средств. В данной работе используется система TensorFlow.

\section[Результаты экспериментальных модельных исследований]
{Результаты экспериментальных модельных \\исследований} 

Результаты.

\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}

\begin{thebibliography}{9}

\begin{hyphenrules}{nohyphenation} 

\begin{sloppypar}

%\item TODO: cite Чубич, Черникова ! mono + guide

\bibitem{denisov} Активная параметрическая идентификация стохастических
линейных систем: монография / В.И. Денисов, В.М. Чубич, О.С. Черникова, Д.И.
Бобылева. --- Новосибирск : Изд-во НГТУ, 2009. --- 192 с. (Серия <<Монографии
НГТУ>>).

\bibitem{chubich} Активная параметрическая идентификация стохастических
динамических систем. Оценивание параметров: учеб. пособие / В.М. Чубич, Е.В.
Филиппова. --- Новосибирск: Изд-во НГТУ, 2016. --- 63 с.

\bibitem{shalom} Bar-Shalom, Yaakov. Estimation with Application to Tracking
and Navigation / by Yaakov Bar-Shalom, X.-Rong Li, Thiagalingam Kirubarajan. 
	- 2001.

\bibitem{ogarkov} Огарков М. А. Методы статистического оценивания параметров
случайных процессов. --- М.: Энергоатомиздат, 1990. --- 208 с.: ил.

\end{sloppypar}

\end{hyphenrules}

\end{thebibliography}

\begin{appendices}

\section{Исходные тексты программ}

\subsection{Вычисление критерия идентификации}

\subsection{Вычисление градиента критерия идентификации}

\end{appendices}

\end{document}

# vim: ts=2 sw=2
